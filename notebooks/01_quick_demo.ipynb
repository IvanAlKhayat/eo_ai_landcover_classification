{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è EO-AI Portfolio: Quick Demo\n",
    "\n",
    "**Land Cover Classification from Sentinel-2 Imagery**\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Data loading and preprocessing\n",
    "2. Model inference\n",
    "3. Visualization of results\n",
    "4. Performance metrics\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/EO-AI-Portfolio/blob/main/notebooks/01_quick_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment for Colab)\n",
    "# !pip install torch torchvision albumentations matplotlib seaborn\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a small synthetic dataset\n",
    "!python ../data/download_bigearthnet_subset.py --output ../data/demo --num_samples 100\n",
    "\n",
    "print(\"‚úÖ Dataset created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess import Sentinel2Dataset, get_transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load dataset\n",
    "dataset = Sentinel2Dataset(\n",
    "    '../data/demo',\n",
    "    split='train',\n",
    "    transform=get_transforms('val')  # No augmentation for visualization\n",
    ")\n",
    "\n",
    "# Visualize first 4 samples\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "CLASS_COLORS = np.array([\n",
    "    [230, 0, 0], [180, 0, 0], [255, 255, 0], [240, 150, 0],\n",
    "    [150, 255, 0], [200, 200, 0], [0, 150, 0], [150, 200, 150],\n",
    "    [200, 200, 200], [0, 100, 200]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    h, w = mask.shape\n",
    "    colored = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for i in range(10):\n",
    "        colored[mask == i] = CLASS_COLORS[i]\n",
    "    return colored\n",
    "\n",
    "for i in range(4):\n",
    "    image, mask = dataset[i]\n",
    "    \n",
    "    # Convert to numpy\n",
    "    image_np = image.numpy().transpose(1, 2, 0)  # (4, H, W) -> (H, W, 4)\n",
    "    mask_np = mask.numpy()\n",
    "    \n",
    "    # RGB composite\n",
    "    rgb = image_np[:, :, :3]\n",
    "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "    \n",
    "    # NIR band\n",
    "    nir = image_np[:, :, 3]\n",
    "    \n",
    "    # Colored mask\n",
    "    colored_mask = colorize_mask(mask_np)\n",
    "    \n",
    "    # Plot\n",
    "    axes[i, 0].imshow(rgb)\n",
    "    axes[i, 0].set_title(f'Sample {i+1}: RGB')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(nir, cmap='gray')\n",
    "    axes[i, 1].set_title('NIR Band')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(colored_mask)\n",
    "    axes[i, 2].set_title('Land Cover Mask')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Train a Quick Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training for 5 epochs\n",
    "!python ../train.py \\\n",
    "    --data_path ../data/demo \\\n",
    "    --epochs 5 \\\n",
    "    --batch_size 4 \\\n",
    "    --lr 1e-3 \\\n",
    "    --checkpoint_dir ../checkpoints_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import get_model\n",
    "from inference import predict_single_image, colorize_mask\n",
    "import time\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(n_channels=4, n_classes=10)\n",
    "\n",
    "# Load checkpoint (if available)\n",
    "checkpoint_path = Path('../checkpoints_demo/best_model.pth')\n",
    "if checkpoint_path.exists():\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"‚úÖ Model loaded!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint found, using random weights\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test samples\n",
    "test_dataset = Sentinel2Dataset(\n",
    "    '../data/demo',\n",
    "    split='test',\n",
    "    transform=get_transforms('val')\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for i in range(3):\n",
    "    image_tensor, mask_gt = test_dataset[i]\n",
    "    image_np = image_tensor.numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        image_input = image_tensor.unsqueeze(0).to(device)\n",
    "        start = time.time()\n",
    "        output = model(image_input)\n",
    "        inference_time = (time.time() - start) * 1000\n",
    "        \n",
    "        prediction = output.argmax(dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # Visualize\n",
    "    rgb = image_np[:, :, :3]\n",
    "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "    \n",
    "    axes[i, 0].imshow(rgb)\n",
    "    axes[i, 0].set_title(f'Input RGB')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(colorize_mask(prediction))\n",
    "    axes[i, 1].set_title(f'Prediction ({inference_time:.1f}ms)')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(colorize_mask(mask_gt.numpy()))\n",
    "    axes[i, 2].set_title('Ground Truth')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Collect predictions\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        image, mask = test_dataset[i]\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        output = model(image)\n",
    "        pred = output.argmax(dim=1).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        all_preds.append(pred.flatten())\n",
    "        all_targets.append(mask.numpy().flatten())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# Calculate mIoU\n",
    "ious = []\n",
    "for cls in range(10):\n",
    "    pred_mask = all_preds == cls\n",
    "    target_mask = all_targets == cls\n",
    "    \n",
    "    intersection = (pred_mask & target_mask).sum()\n",
    "    union = (pred_mask | target_mask).sum()\n",
    "    \n",
    "    if union > 0:\n",
    "        ious.append(intersection / union)\n",
    "\n",
    "miou = np.mean(ious)\n",
    "accuracy = (all_preds == all_targets).sum() / len(all_targets)\n",
    "\n",
    "print(f\"\\nüìä Metrics:\")\n",
    "print(f\"  mIoU: {miou:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Model Compression Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark original model\n",
    "import time\n",
    "\n",
    "def benchmark_model(model, input_shape=(1, 4, 256, 256), num_runs=100):\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = np.mean(times) * 1000  # ms\n",
    "    return avg_time\n",
    "\n",
    "original_time = benchmark_model(model)\n",
    "\n",
    "print(f\"‚è±Ô∏è Original model inference: {original_time:.2f} ms\")\n",
    "print(f\"üöÄ FPS: {1000/original_time:.2f}\")\n",
    "\n",
    "# Note: Full quantization requires CPU and calibration data\n",
    "# See models/quantization.py for complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ‚úÖ Synthetic Sentinel-2 data generation\n",
    "- ‚úÖ U-Net model for land cover classification\n",
    "- ‚úÖ Inference and visualization\n",
    "- ‚úÖ Performance metrics (mIoU, accuracy)\n",
    "\n",
    "### Next Steps:\n",
    "1. Train on real BigEarthNet data\n",
    "2. Apply INT8 quantization for 3x compression\n",
    "3. Deploy with Docker\n",
    "4. Scale with multi-GPU DDP training\n",
    "\n",
    "### Links:\n",
    "- üìñ [README](../README.md)\n",
    "- üêô [GitHub Repository](https://github.com/yourusername/EO-AI-Portfolio)\n",
    "- üìÑ [Full Documentation](../README.md#documentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
